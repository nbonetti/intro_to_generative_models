{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5467d0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn.functional as F \n",
    "import random \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ce1345f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BONETTI\\Desktop\\3A\\Intro to generative models\\.conda\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargement du tokenizer...\n",
      "Téléchargement du modèle...\n",
      "Modèle chargé sur cpu !\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "# On choisit un modèle très léger (environ 500 Mo)\n",
    "model_name = \"facebook/opt-125m\" \n",
    "\n",
    "print(\"Téléchargement du tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "print(\"Téléchargement du modèle...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# On déplace le modèle sur le GPU si disponible, sinon CPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "print(f\"Modèle chargé sur {device} !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17c5f987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def compute_log_likelihood(model, tokenizer, sequence):\n",
    "    \"\"\"Calcule la log-vraisemblance log(p(x)) d'une séquence.\"\"\"\n",
    "    inputs = tokenizer(sequence, return_tensors=\"pt\").to(model.device)\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, labels=input_ids)\n",
    "        # Le modèle renvoie déjà la CrossEntropy (Negative Log Likelihood moyenne)\n",
    "        # On la multiplie par le nombre de tokens pour avoir la somme des log-probs\n",
    "        log_p_x = -outputs.loss.item() * (input_ids.shape[1] - 1)\n",
    "        \n",
    "    return log_p_x, inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "524436e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Départ: The most important number in math is | Log P: -26.93\n",
      "Étape 1: REJETÉ | Nouveau texte: The most important number in the world, it was a 9... | Log P: -56.22\n",
      "Étape 2: REJETÉ | Nouveau texte: The most important number of words: EASILY, EASILY... | Log P: -64.79\n",
      "Étape 3: REJETÉ | Nouveau texte: The most important number would be 8, and the most... | Log P: -51.16\n",
      "Étape 4: REJETÉ | Nouveau texte: The most important number of times I know the word... | Log P: -67.34\n",
      "Étape 5: REJETÉ | Nouveau texte: The most important number to use is the \"T\" in the... | Log P: -59.06\n",
      "Étape 6: REJETÉ | Nouveau texte: The most important number of people I know, and pr... | Log P: -53.93\n",
      "Étape 7: REJETÉ | Nouveau texte: The most important number is the number of days a ... | Log P: -56.81\n",
      "Étape 8: REJETÉ | Nouveau texte: The most important number is 6.  This isn't even a... | Log P: -57.98\n",
      "Étape 9: REJETÉ | Nouveau texte: The most important number in any city in the world... | Log P: -60.26\n",
      "Étape 10: REJETÉ | Nouveau texte: The most important number for this is the total nu... | Log P: -51.60\n",
      "Étape 11: REJETÉ | Nouveau texte: The most important number for you is 10, right?\n",
      "I'... | Log P: -58.99\n",
      "Étape 12: REJETÉ | Nouveau texte: The most important number of women are a few years... | Log P: -58.75\n",
      "Étape 13: REJETÉ | Nouveau texte: The most important number about the “big” news in ... | Log P: -58.39\n",
      "Étape 14: REJETÉ | Nouveau texte: The most important number of times I played a hero... | Log P: -64.03\n",
      "Étape 15: REJETÉ | Nouveau texte: The most important number is the *H* rather than t... | Log P: -51.87\n",
      "Étape 16: REJETÉ | Nouveau texte: The most important number to note is that you don'... | Log P: -63.34\n",
      "Étape 17: REJETÉ | Nouveau texte: The most important number one on your schedule is ... | Log P: -58.32\n",
      "Étape 18: REJETÉ | Nouveau texte: The most important number to be using is the 10%, ... | Log P: -64.09\n",
      "Étape 19: REJETÉ | Nouveau texte: The most important number is 8, so just for compar... | Log P: -66.69\n",
      "Étape 20: REJETÉ | Nouveau texte: The most important number isn't even in the stats ... | Log P: -60.78\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def run_correction_tracker(model, tokenizer, initial_text, alpha=15.0, steps=10, block_size=15):\n",
    "    current_text = initial_text\n",
    "    # Calcul initial\n",
    "    current_log_p, _ = compute_log_likelihood(model, tokenizer, current_text)\n",
    "    \n",
    "    history = []\n",
    "    history.append({\"step\": 0, \"text\": current_text, \"log_p\": current_log_p, \"status\": \"Initial\"})\n",
    "\n",
    "    print(f\"Départ: {current_text} | Log P: {current_log_p:.2f}\")\n",
    "\n",
    "    for i in range(1, steps + 1):\n",
    "        # 1. On transforme le texte en IDs pour manipuler les blocs\n",
    "        input_ids = tokenizer.encode(current_text, return_tensors=\"pt\").to(model.device)\n",
    "        seq_len = input_ids.shape[1]\n",
    "\n",
    "        # 2. Choisir un bloc à modifier (on évite le tout début)\n",
    "        start_idx = random.randint(min(5, seq_len-1), max(5, seq_len - block_size - 1))\n",
    "        prefix_ids = input_ids[:, :start_idx]\n",
    "\n",
    "        # 3. Proposer un nouveau bloc (x')\n",
    "        with torch.no_grad():\n",
    "            new_block_ids = model.generate(\n",
    "                prefix_ids, \n",
    "                max_new_tokens=block_size, \n",
    "                do_sample=True, \n",
    "                temperature=1.0, # On échantillonne normalement\n",
    "                attention_mask=prefix_ids.ne(tokenizer.pad_token_id).long(),\n",
    "                pad_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "        \n",
    "        proposed_text = tokenizer.decode(new_block_ids[0], skip_special_tokens=True)\n",
    "        #print(f\"Phrase complète à cette étape : \\n {proposed_text}\")\n",
    "        proposed_log_p, _ = compute_log_likelihood(model, tokenizer, proposed_text)\n",
    "\n",
    "        # 4. Calcul du ratio Metropolis-Hastings\n",
    "        # log(A) = alpha * (log_p_proposed - log_p_current)\n",
    "        acceptance_log_ratio = alpha * (proposed_log_p - current_log_p)\n",
    "        \n",
    "        accepted = False\n",
    "        if np.log(random.random()) < acceptance_log_ratio:\n",
    "            current_text = proposed_text\n",
    "            current_log_p = proposed_log_p\n",
    "            accepted = True\n",
    "\n",
    "        status = \"ACCEPTÉ\" if accepted else \"REJETÉ\"\n",
    "        print(f\"Étape {i}: {status} | Nouveau texte: {proposed_text[:50]}... | Log P: {proposed_log_p:.2f}\")\n",
    "        \n",
    "        history.append({\n",
    "            \"step\": i, \n",
    "            \"text\": proposed_text, \n",
    "            \"log_p\": proposed_log_p, \n",
    "            \"status\": status,\n",
    "            \"final_text_at_step\": current_text\n",
    "        })\n",
    "\n",
    "    return history\n",
    "\n",
    "# --- TEST ---\n",
    "# On commence volontairement avec une phrase un peu bancale\n",
    "prompt_initial = \"The most important number in math is\"\n",
    "tracker_results = run_correction_tracker(model, tokenizer, prompt_initial, alpha=16, steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9598a60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Départ: The most important number in math is | Log P: -26.93\n",
      "Étape 1: REJETÉ | Nouveau texte: The most important number you can make a statement... | Log P: -34.69\n",
      "Étape 2: REJETÉ | Nouveau texte: The most important number for all of us is... | Log P: -28.69\n",
      "Étape 3: REJETÉ | Nouveau texte: The most important number of people in this game... | Log P: -28.63\n",
      "Étape 4: REJETÉ | Nouveau texte: The most important number to remember to check is... | Log P: -30.03\n",
      "Étape 5: ACCEPTÉ | Nouveau texte: The most important number of people in the world... | Log P: -24.12\n",
      "Étape 6: REJETÉ | Nouveau texte: The most important number of things to know on... | Log P: -32.46\n",
      "Étape 7: REJETÉ | Nouveau texte: The most important number to me is when you... | Log P: -27.64\n",
      "Étape 8: REJETÉ | Nouveau texte: The most important number will be the \"N... | Log P: -33.82\n",
      "Étape 9: REJETÉ | Nouveau texte: The most important number of people my whole life... | Log P: -33.12\n",
      "Étape 10: REJETÉ | Nouveau texte: The most important number is 634.\n",
      "... | Log P: -31.76\n",
      "Départ: The most important number in math is | Log P: -26.93\n",
      "Étape 1: REJETÉ | Nouveau texte: The most important number of days with a home... | Log P: -37.97\n",
      "Étape 2: REJETÉ | Nouveau texte: The most important number is 10, but it... | Log P: -30.30\n",
      "Étape 3: REJETÉ | Nouveau texte: The most important number and then the most import... | Log P: -31.53\n",
      "Étape 4: REJETÉ | Nouveau texte: The most important number for this list is the... | Log P: -30.43\n",
      "Étape 5: REJETÉ | Nouveau texte: The most important number in a song is 10... | Log P: -34.42\n",
      "Étape 6: REJETÉ | Nouveau texte: The most important number I see on this site... | Log P: -30.50\n",
      "Étape 7: REJETÉ | Nouveau texte: The most important number of people are willing to... | Log P: -29.30\n",
      "Étape 8: REJETÉ | Nouveau texte: The most important number of players in this group... | Log P: -33.19\n",
      "Étape 9: REJETÉ | Nouveau texte: The most important number in your chart and the... | Log P: -34.92\n",
      "Étape 10: REJETÉ | Nouveau texte: The most important number for this is the number... | Log P: -28.98\n",
      "Départ: The most important number in math is | Log P: -26.93\n",
      "Étape 1: REJETÉ | Nouveau texte: The most important number of languages spoken in G... | Log P: -35.77\n",
      "Étape 2: REJETÉ | Nouveau texte: The most important number of kids born in India... | Log P: -33.17\n",
      "Étape 3: REJETÉ | Nouveau texte: The most important number is 1.\n",
      "That... | Log P: -27.90\n",
      "Étape 4: REJETÉ | Nouveau texte: The most important number for the entire process i... | Log P: -34.31\n",
      "Étape 5: REJETÉ | Nouveau texte: The most important number could be the amount of... | Log P: -30.31\n",
      "Étape 6: REJETÉ | Nouveau texte: The most important number, I would say,... | Log P: -27.72\n",
      "Étape 7: REJETÉ | Nouveau texte: The most important number is -24? Not... | Log P: -38.81\n",
      "Étape 8: REJETÉ | Nouveau texte: The most important number for me is around 1... | Log P: -29.96\n",
      "Étape 9: REJETÉ | Nouveau texte: The most important number is what i think it... | Log P: -34.59\n",
      "Étape 10: REJETÉ | Nouveau texte: The most important number is the one that's... | Log P: -28.43\n",
      "Départ: The most important number in math is | Log P: -26.93\n",
      "Étape 1: REJETÉ | Nouveau texte: The most important number is the \"you have... | Log P: -32.42\n",
      "Étape 2: REJETÉ | Nouveau texte: The most important number to note this week in... | Log P: -34.18\n",
      "Étape 3: REJETÉ | Nouveau texte: The most important number we have seen was 6... | Log P: -36.80\n",
      "Étape 4: ACCEPTÉ | Nouveau texte: The most important number to note is that the... | Log P: -25.40\n",
      "Étape 5: REJETÉ | Nouveau texte: The most important number is 5.\n",
      "Thank... | Log P: -29.92\n",
      "Étape 6: REJETÉ | Nouveau texte: The most important number (if the title is... | Log P: -38.44\n",
      "Étape 7: REJETÉ | Nouveau texte: The most important number is 4.  When... | Log P: -31.47\n",
      "Étape 8: REJETÉ | Nouveau texte: The most important number on the top right corner... | Log P: -31.28\n",
      "Étape 9: REJETÉ | Nouveau texte: The most important number from my research was 4... | Log P: -36.66\n",
      "Étape 10: REJETÉ | Nouveau texte: The most important number to this story is in... | Log P: -34.14\n",
      "Départ: The most important number in math is | Log P: -26.93\n",
      "Étape 1: REJETÉ | Nouveau texte: The most important number to note is that those... | Log P: -29.40\n",
      "Étape 2: REJETÉ | Nouveau texte: The most important number of questions about the f... | Log P: -33.14\n",
      "Étape 3: ACCEPTÉ | Nouveau texte: The most important number of countries in the worl... | Log P: -26.40\n",
      "Étape 4: REJETÉ | Nouveau texte: The most important number, even, as soon... | Log P: -43.07\n",
      "Étape 5: REJETÉ | Nouveau texte: The most important number is the last number..... | Log P: -33.75\n",
      "Étape 6: REJETÉ | Nouveau texte: The most important number is 4 digits. If... | Log P: -32.79\n",
      "Étape 7: REJETÉ | Nouveau texte: The most important number.\n",
      "Why the hell... | Log P: -32.42\n",
      "Étape 8: REJETÉ | Nouveau texte: The most important number of days before work is... | Log P: -36.56\n",
      "Étape 9: REJETÉ | Nouveau texte: The most important number of deaths in Germany has... | Log P: -32.82\n",
      "Étape 10: REJETÉ | Nouveau texte: The most important number is the 0.5... | Log P: -29.97\n",
      "\n",
      "--- RÉSULTATS ---\n",
      "GREEDY: The most important number in math is the number of times you have to use the word \"I\" to make a statement.\n",
      "I | LogP: -58.78\n",
      "POWER : The most important number in math is | LogP: -28.43\n"
     ]
    }
   ],
   "source": [
    "def compare_greedy_vs_power(model, tokenizer, prompt, alpha=15.0):\n",
    "    # 1. Génération Greedy (Standard)\n",
    "    greedy_output = model.generate(\n",
    "        tokenizer(prompt, return_tensors=\"pt\").input_ids.to(model.device),\n",
    "        max_new_tokens=20,\n",
    "        do_sample=False # Mode Greedy\n",
    "    )\n",
    "    greedy_text = tokenizer.decode(greedy_output[0], skip_special_tokens=True)\n",
    "    greedy_log_p, _ = compute_log_likelihood(model, tokenizer, greedy_text)\n",
    "\n",
    "    # 2. Génération Power Sampling (On prend le meilleur de 5 chaînes MCMC)\n",
    "    power_results = []\n",
    "    for i in range(5):\n",
    "        # On lance un MCMC court\n",
    "        trace = run_correction_tracker(model, tokenizer, prompt, alpha=alpha, steps=10, block_size=5)\n",
    "        final_version = trace[-1]\n",
    "        power_results.append(final_version)\n",
    "\n",
    "    # Trier pour trouver le meilleur résultat Power Sampling\n",
    "    best_power = max(power_results, key=lambda x: x['log_p'])\n",
    "\n",
    "    print(\"\\n--- RÉSULTATS ---\")\n",
    "    print(f\"GREEDY: {greedy_text} | LogP: {greedy_log_p:.2f}\")\n",
    "    print(f\"POWER : {best_power['final_text_at_step']} | LogP: {best_power['log_p']:.2f}\")\n",
    "    \n",
    "    return greedy_log_p, best_power['log_p']\n",
    "\n",
    "# Test\n",
    "g_score, p_score = compare_greedy_vs_power(model, tokenizer, \"The most important number in math is\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
